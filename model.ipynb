{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "#import modin.pandas as pd\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import music21\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total labels: 464\n"
     ]
    }
   ],
   "source": [
    "# load note coding labels \n",
    "labels = pd.read_csv('output/labelled_notes.csv')\n",
    "labels = labels.values.tolist()\n",
    "\n",
    "print('total labels:', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>a1.0_0.125</th>\n",
       "      <th>a1.0_0.25</th>\n",
       "      <th>a1.0_0.3333333333333333</th>\n",
       "      <th>a1.0_0.5</th>\n",
       "      <th>a1.0_0.75</th>\n",
       "      <th>a1.0_1.0</th>\n",
       "      <th>a1.0_1.5</th>\n",
       "      <th>a1.0_2.0</th>\n",
       "      <th>a2.0_0.125</th>\n",
       "      <th>...</th>\n",
       "      <th>r_1.25</th>\n",
       "      <th>r_1.5</th>\n",
       "      <th>r_2.0</th>\n",
       "      <th>x_0.125</th>\n",
       "      <th>x_0.25</th>\n",
       "      <th>x_0.5</th>\n",
       "      <th>x_0.75</th>\n",
       "      <th>x_1.0</th>\n",
       "      <th>x_1.5</th>\n",
       "      <th>x_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412378</th>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412379</th>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412380</th>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412381</th>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412382</th>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>412383 rows × 465 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        song  a1.0_0.125  a1.0_0.25  a1.0_0.3333333333333333  a1.0_0.5  \\\n",
       "0          1           0          0                        0         0   \n",
       "1          1           0          0                        0         0   \n",
       "2          1           0          0                        0         0   \n",
       "3          1           0          0                        0         0   \n",
       "4          1           0          0                        0         0   \n",
       "...      ...         ...        ...                      ...       ...   \n",
       "412378   410           0          0                        0         0   \n",
       "412379   410           0          0                        0         0   \n",
       "412380   410           0          0                        0         0   \n",
       "412381   410           0          0                        0         0   \n",
       "412382   410           0          0                        0         0   \n",
       "\n",
       "        a1.0_0.75  a1.0_1.0  a1.0_1.5  a1.0_2.0  a2.0_0.125  ...  r_1.25  \\\n",
       "0               0         0         0         0           0  ...       0   \n",
       "1               0         0         0         0           0  ...       0   \n",
       "2               0         0         0         0           0  ...       0   \n",
       "3               0         0         0         0           0  ...       0   \n",
       "4               0         0         0         0           0  ...       0   \n",
       "...           ...       ...       ...       ...         ...  ...     ...   \n",
       "412378          0         0         0         0           0  ...       0   \n",
       "412379          0         0         0         0           0  ...       0   \n",
       "412380          0         0         0         0           0  ...       0   \n",
       "412381          0         0         0         0           0  ...       0   \n",
       "412382          0         0         0         0           0  ...       0   \n",
       "\n",
       "        r_1.5  r_2.0  x_0.125  x_0.25  x_0.5  x_0.75  x_1.0  x_1.5  x_2.0  \n",
       "0           0      0        0       0      0       0      0      0      0  \n",
       "1           0      0        0       0      0       0      0      0      0  \n",
       "2           0      0        0       0      0       0      0      0      0  \n",
       "3           0      0        0       0      0       0      0      0      0  \n",
       "4           0      0        0       0      0       0      0      0      0  \n",
       "...       ...    ...      ...     ...    ...     ...    ...    ...    ...  \n",
       "412378      0      0        0       0      0       0      0      0      0  \n",
       "412379      0      0        0       0      0       0      0      0      0  \n",
       "412380      0      0        0       0      0       0      0      0      0  \n",
       "412381      0      0        0       0      0       0      0      0      0  \n",
       "412382      0      0        0       0      0       0      0      0      0  \n",
       "\n",
       "[412383 rows x 465 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('output/processed_output.csv')\n",
    "#df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def process_row(row):\n",
    "\n",
    "maxlen = 32\n",
    "step = 1\n",
    "dim = len(labels)\n",
    "#df = df[df['song'] == 1]\n",
    "\n",
    "def old_create_batches():\n",
    "    sequences = np.zeros(shape=(len(df), maxlen, dim), dtype=np.int8)\n",
    "    next_notes = np.zeros(shape=(len(df), dim), dtype=np.int8)\n",
    "\n",
    "    songs_count = len(df['song'].unique())\n",
    "\n",
    "    batch_id = 0\n",
    "    for song_idx in range(1, songs_count):\n",
    "        df_part = df[df['song'] == song_idx]\n",
    "        df_part.drop(columns=['song'], inplace=True)\n",
    "        length = len(df_part) - maxlen - 1\n",
    "    \n",
    "        for slice_start in range(0, length, step):\n",
    "            sample_id = 0\n",
    "            for row in df_part[slice_start: maxlen + slice_start].iterrows():\n",
    "            \n",
    "                sequences[batch_id][sample_id] = row[1]\n",
    "            \n",
    "                sample_id += 1\n",
    "            next_notes[batch_id] = row[1]\n",
    "            batch_id += 1\n",
    "            \n",
    "    return sequences, next_notes, songs_count\n",
    "\n",
    "            \n",
    "def create_batches(): #94% better perf\n",
    "    sequences = np.zeros(shape=(len(df), maxlen, dim), dtype=np.int8)\n",
    "    next_notes = np.zeros(shape=(len(df), dim), dtype=np.int8)\n",
    "\n",
    "    songs_count = len(df['song'].unique())\n",
    "\n",
    "    batch_id = 0\n",
    "    for song_idx in range(1, songs_count):\n",
    "        df_part = df[df['song'] == song_idx]\n",
    "        df_part.drop(columns=['song'], inplace=True)\n",
    "        bucket_count = len(df_part) - maxlen - 1\n",
    "    \n",
    "        for slice_start in range(0, bucket_count, step):\n",
    "\n",
    "            next_notes[batch_id] = df_part.iloc[maxlen + slice_start + 1]\n",
    "            sequences[batch_id] = df_part[slice_start: maxlen + slice_start].to_numpy()\n",
    "            batch_id += 1\n",
    "            \n",
    "    return sequences, next_notes, songs_count\n",
    "\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "sequences, next_notes, songs_count = create_batches()\n",
    "\n",
    "t2 = time.time()\n",
    "print (t2 - t1)  \n",
    "\n",
    "#t1 = time.time()\n",
    "#sequences, next_notes, songs_count = old_create_batches()\n",
    "\n",
    "#t2 = time.time()\n",
    "#print (t2 - t1)  \n",
    "\n",
    "print('nb songs: ', songs_count)\n",
    "print('nb sequences:', len(sequences))\n",
    "print('nb next_notes:', len(next_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "labels_count = len(labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=True, activation=tfa.activations.gelu))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=False, activation=tfa.activations.gelu))\n",
    "model.add(Dense(512, activation=tfa.activations.gelu))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(labels_count, activation='softmax'))\n",
    "\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "import tensorflow_addons as tfa\n",
    "labels_count = len(labels)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(512, return_sequences=True, activation=\"relu\")))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(512, return_sequences=False, activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(labels_count, activation='softmax'))\n",
    "\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print('model 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def decode(index):\n",
    "    return labels[index][0]\n",
    "\n",
    "def sequence_to_label(sequence):\n",
    "    result = []\n",
    "    for index, data in sequence.iterrows():\n",
    "        for label, content in data.items():\n",
    "            if content > 0 :\n",
    "                result.append(label)\n",
    "    return result\n",
    "\n",
    "def export_to_midi(string, name):\n",
    "    notes = string.strip().split(' ')\n",
    "    s = music21.stream.Stream()\n",
    "    for row in notes:\n",
    "        data = row.split(\"-\")\n",
    "        note = data[0]\n",
    "        duration= float(data[1])\n",
    "    \n",
    "        if not note == 'x':\n",
    "            if note == 'r':\n",
    "                s.append(music21.note.Rest(quarterLength=duration))\n",
    "            else:\n",
    "                s.append(music21.note.Note(note, quarterLength=duration))\n",
    "\n",
    "    print(s)\n",
    "    s.write(\"midi\", 'predicted/' + name)\n",
    "    \n",
    "def get_file_name(epoch, diversity):\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y%m%d%H%M\") + '_' +str(epoch) +'_' + str(diversity) + '.mid'\n",
    "    \n",
    "def get_seed():\n",
    "    return df_copy[start_index: start_index + maxlen]\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(df) - maxlen - 1)\n",
    "    start_index = 128\n",
    "    for diversity in [0.2,0.3,0.4,0.5,0.6]:\n",
    "        print('----- diversity:', diversity)\n",
    "        \n",
    "        df_copy = df.drop(columns=['song'])\n",
    "        sequence = df_copy[start_index: start_index + maxlen]\n",
    "        \n",
    "        #print('----- Generating with seed: \"' + ','.join(sequence_to_label(sequence)) + '\"') \n",
    "        #print()\n",
    "        predicted = ''\n",
    "        for i in range(1024):\n",
    "            # czary mary\n",
    "            sequences = np.zeros(shape=(1, maxlen, len(labels)), dtype=float)\n",
    "            np.append(sequences, sequence)\n",
    "            x_pred = sequences\n",
    "\n",
    "            # predicting \n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            \n",
    "            \n",
    "            next_char = decode(next_index)\n",
    "\n",
    "            #adding new note TODO\n",
    "            new_note = np.zeros(shape=(len(labels)), dtype=float)\n",
    "            new_note[next_index] = 1\n",
    "            \n",
    "            sequence = sequence[1:]\n",
    "            sequence.append(pd.DataFrame(new_note), ignore_index=True)\n",
    "            \n",
    "            #add\n",
    "            predicted += next_char + ' '\n",
    "            #writing\n",
    "            sys.stdout.write(next_char + ' ')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        export_to_midi(predicted, get_file_name(epoch, diversity))\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "\n",
    "history = model.fit(sequences, next_notes,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          callbacks=[print_callback])\n",
    "\n",
    "#shuffle??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_7 to have 3 dimensions, but got array with shape (476662, 461)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7a835c73ed4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m history = model.fit(sequences, [next_notes, next_notes],\n\u001b[1;32m     35\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           epochs=10)\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mdf_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'song'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_7 to have 3 dimensions, but got array with shape (476662, 461)"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "labels_count = len(labels)\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(maxlen, labels_count),  name='inputs')\n",
    "\n",
    "\n",
    "#model1 = Sequential()\n",
    "#model1.add(LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count)))\n",
    "#model1.add(Dropout(0.3))\n",
    "#model1.add(LSTM(512, return_sequences=True, activation=\"relu\"))\n",
    "#model1.add(Dropout(0.3))\n",
    "#model1.add(LSTM(512, return_sequences=False, activation=\"relu\"))\n",
    "\n",
    "x1 = LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count))(inputs)\n",
    "model1_out = Dense(labels_count, activation='softmax')(x1)\n",
    "\n",
    "#model2 = Sequential()\n",
    "#model2.add(LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count)))\n",
    "#model2.add(Dropout(0.3))\n",
    "#model2.add(LSTM(512, return_sequences=True, activation=tfa.activations.gelu))\n",
    "#model2.add(Dropout(0.3))\n",
    "#model2.add(LSTM(512, return_sequences=False, activation=tfa.activations.gelu))\n",
    "\n",
    "x2 = LSTM(512, return_sequences=True, input_shape=(maxlen, labels_count))(inputs)\n",
    "model2_out = Dense(labels_count, activation='softmax')(x2)\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[model1_out, model2_out])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', loss_weights=[1., 0.5])\n",
    "\n",
    "history = model.fit(sequences, [next_notes, next_notes],\n",
    "          batch_size=128,\n",
    "          epochs=10)\n",
    "\n",
    "df_copy = df.drop(columns=['song'])\n",
    "sequence = df_copy[start_index: start_index + maxlen]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in [\"acc\"]:\n",
    "    plt.plot(history.history[label],label=label)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "for label in [\"loss\"]:\n",
    "    plt.plot(history.history[label],label=label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
